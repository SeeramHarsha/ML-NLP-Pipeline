{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk2ohTnY_KC0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra spaces and punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.strip()\n",
        "\n",
        "def preprocess_data(input_file, output_file):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Remove missing values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Clean the text replies\n",
        "    df['reply'] = df['reply'].apply(clean_text)\n",
        "\n",
        "    # Standardize labels to lowercase\n",
        "    df['label'] = df['label'].str.lower()\n",
        "\n",
        "    # Save the cleaned data\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocess_data('/content/Data/emails.csv', '/content/Data/cleaned_emails.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "\n",
        "def train_baseline_model(input_file, model_output_path, vectorizer_output_path):\n",
        "    # Load the cleaned dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X = df['reply']\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize TF-IDF Vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "    # Fit and transform the training data\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "    # Transform the test data\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "    # Train a Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Baseline Model Accuracy: {accuracy}\")\n",
        "    print(f\"Baseline Model F1 Score: {f1}\")\n",
        "\n",
        "    # Save the trained model and vectorizer\n",
        "    joblib.dump(model, model_output_path)\n",
        "    joblib.dump(tfidf_vectorizer, vectorizer_output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_baseline_model(\n",
        "        '/content/Data/cleaned_emails.csv',\n",
        "        '/content/models/baseline_model.joblib',\n",
        "        '/content/models/tfidf_vectorizer.joblib'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhFMv9ThCva5",
        "outputId": "4b2a9364-dbaa-4179-fffc-8003cefd6c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model Accuracy: 0.9953051643192489\n",
            "Baseline Model F1 Score: 0.9952978860372445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer, IntervalStrategy\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "def train_transformer_model(input_file, model_output_dir):\n",
        "    # Load the cleaned dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Map labels to integers\n",
        "    unique_labels = df['label'].unique()\n",
        "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
        "    int_to_label = {i: label for i, label in enumerate(unique_labels)}\n",
        "    df['label_int'] = df['label'].map(label_to_int)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['reply'], df['label_int'], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Tokenize data\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    train_encodings = tokenize_function(X_train.tolist())\n",
        "    test_encodings = tokenize_function(X_test.tolist())\n",
        "\n",
        "    # Create Hugging Face Dataset\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'input_ids': train_encodings['input_ids'],\n",
        "        'attention_mask': train_encodings['attention_mask'],\n",
        "        'labels': y_train.tolist()\n",
        "    })\n",
        "    test_dataset = Dataset.from_dict({\n",
        "        'input_ids': test_encodings['input_ids'],\n",
        "        'attention_mask': test_encodings['attention_mask'],\n",
        "        'labels': y_test.tolist()\n",
        "    })\n",
        "\n",
        "    # Load model\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=len(unique_labels)\n",
        "    )\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        # logging_dir='./logs', # Removed for simplicity\n",
        "        # logging_steps=10, # Removed for simplicity\n",
        "        # evaluation_strategy=IntervalStrategy.EPOCH, # Removed due to TypeError\n",
        "        # save_strategy=IntervalStrategy.EPOCH, # Removed due to TypeError\n",
        "        # load_best_model_at_end=True, # Removed due to TypeError\n",
        "        # metric_for_best_model=\"f1\", # Removed due to TypeError\n",
        "        report_to=\"none\" # Disable reporting to services like W&B\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the fine-tuned model\n",
        "    trainer.save_model(model_output_dir)\n",
        "    tokenizer.save_pretrained(model_output_dir)\n",
        "\n",
        "    # Save label mappings\n",
        "    pd.DataFrame([int_to_label]).to_csv(f\"{model_output_dir}/label_mapping.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_transformer_model(\n",
        "        '/content/Data/cleaned_emails.csv',\n",
        "        './content/models/distilbert_finetuned'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "GC4La2orDGyZ",
        "outputId": "740b4e3a-ac9a-44a4-bb5b-fa30a87f5c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [639/639 08:51, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.222000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def evaluate_baseline_model(input_file, model_path, vectorizer_path):\n",
        "    df = pd.read_csv(input_file)\n",
        "    X = df['reply']\n",
        "    y = df['label']\n",
        "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = joblib.load(model_path)\n",
        "    vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "def evaluate_transformer_model(input_file, model_dir):\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Load label mapping\n",
        "    label_mapping_df = pd.read_csv(f\"{model_dir}/label_mapping.csv\")\n",
        "    # Ensure keys are integers\n",
        "    int_to_label = {int(k): v for k, v in label_mapping_df.iloc[0].to_dict().items()}\n",
        "    label_to_int = {v: k for k, v in int_to_label.items()}\n",
        "\n",
        "    df['label_int'] = df['label'].map(label_to_int)\n",
        "\n",
        "    X = df['reply']\n",
        "    y = df['label_int']\n",
        "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_dir)\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for text, label in zip(X_test, y_test):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_label_int = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append(pred_label_int)\n",
        "        true_labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cleaned_data_path = '/content/Data/cleaned_emails.csv'\n",
        "    baseline_model_path = '/content/models/baseline_model.joblib'\n",
        "    tfidf_vectorizer_path = '/content/models/tfidf_vectorizer.joblib'\n",
        "    transformer_model_dir = './content/models/distilbert_finetuned'\n",
        "\n",
        "    print(\"Evaluating Baseline Model...\")\n",
        "    baseline_accuracy, baseline_f1 = evaluate_baseline_model(\n",
        "        cleaned_data_path, baseline_model_path, tfidf_vectorizer_path\n",
        "    )\n",
        "    print(f\"Baseline Model - Accuracy: {baseline_accuracy:.4f}, F1 Score: {baseline_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nEvaluating Transformer Model...\")\n",
        "    transformer_accuracy, transformer_f1 = evaluate_transformer_model(\n",
        "        cleaned_data_path, transformer_model_dir\n",
        "    )\n",
        "    print(f\"Transformer Model - Accuracy: {transformer_accuracy:.4f}, F1 Score: {transformer_f1:.4f}\")\n",
        "\n",
        "    # Compare and decide\n",
        "    if transformer_f1 > baseline_f1:\n",
        "        print(\"\\nTransformer model performs better and is recommended for production.\")\n",
        "        best_model = \"Transformer\"\n",
        "    else:\n",
        "        print(\"\\nBaseline model performs better and is recommended for production.\")\n",
        "        best_model = \"Baseline\"\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        \"baseline_model\": {\n",
        "            \"accuracy\": baseline_accuracy,\n",
        "            \"f1_score\": baseline_f1\n",
        "        },\n",
        "        \"transformer_model\": {\n",
        "            \"accuracy\": transformer_accuracy,\n",
        "            \"f1_score\": transformer_f1\n",
        "        },\n",
        "        \"best_model_for_production\": best_model\n",
        "    }\n",
        "\n",
        "    with open('/content/Results/model_comparison.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "    print(\"\\nModel comparison results saved to results/model_comparison.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mARUwFT2F2eQ",
        "outputId": "31f09fcb-730d-46b8-da71-59afb3c4dcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Baseline Model...\n",
            "Baseline Model - Accuracy: 0.9953, F1 Score: 0.9953\n",
            "\n",
            "Evaluating Transformer Model...\n",
            "Transformer Model - Accuracy: 1.0000, F1 Score: 1.0000\n",
            "\n",
            "Transformer model performs better and is recommended for production.\n",
            "\n",
            "Model comparison results saved to results/model_comparison.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import uvicorn\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Define input and output models for FastAPI\n",
        "class PredictionRequest(BaseModel):\n",
        "    text: str\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    label: str\n",
        "    confidence: float\n",
        "\n",
        "# Load the fine-tuned transformer model and tokenizer\n",
        "model_dir = \"./content/models/distilbert_finetuned\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_dir)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Load label mapping\n",
        "label_mapping_path = os.path.join(model_dir, \"label_mapping.csv\")\n",
        "label_mapping_df = pd.read_csv(label_mapping_path)\n",
        "int_to_label = {int(k): v for k, v in label_mapping_df.iloc[0].to_dict().items()}\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "    return {\"message\": \"NLP Email Classifier API. Use /predict to get predictions.\"}\n",
        "\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict(request: PredictionRequest):\n",
        "    text = request.text\n",
        "\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)[0]\n",
        "\n",
        "    # Get predicted label and confidence\n",
        "    predicted_label_id = torch.argmax(probabilities).item()\n",
        "    confidence = probabilities[predicted_label_id].item()\n",
        "    predicted_label = int_to_label[predicted_label_id]\n",
        "\n",
        "    return PredictionResponse(label=predicted_label, confidence=confidence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "eObAkqmWo4DI",
        "outputId": "87703a57-b4a8-4d95-f066-cb691e714e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for './content/models/distilbert_finetuned'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './content/models/distilbert_finetuned' is the correct path to a directory containing all relevant files for a DistilBertTokenizerFast tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './content/models/distilbert_finetuned'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1966\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1967\u001b[0;31m                         resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1968\u001b[0m                             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \"\"\"\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         resolved_files = [\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './content/models/distilbert_finetuned'. Use `repo_type` argument if needed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-193489392.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load the fine-tuned transformer model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./content/models/distilbert_finetuned\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m                         \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m                         raise OSError(\n\u001b[0m\u001b[1;32m   1988\u001b[0m                             \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m                             \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for './content/models/distilbert_finetuned'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './content/models/distilbert_finetuned' is the correct path to a directory containing all relevant files for a DistilBertTokenizerFast tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11aEDdFfo8Mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}