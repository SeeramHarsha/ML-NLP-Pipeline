{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yk2ohTnY_KC0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra spaces and punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text.strip()\n",
        "\n",
        "def preprocess_data(input_file, output_file):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Remove missing values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Clean the text replies\n",
        "    df['reply'] = df['reply'].apply(clean_text)\n",
        "\n",
        "    # Standardize labels to lowercase\n",
        "    df['label'] = df['label'].str.lower()\n",
        "\n",
        "    # Save the cleaned data\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocess_data('/content/Data/emails.csv', '/content/Data/cleaned_emails.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "\n",
        "def train_baseline_model(input_file, model_output_path, vectorizer_output_path):\n",
        "    # Load the cleaned dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X = df['reply']\n",
        "    y = df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize TF-IDF Vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "    # Fit and transform the training data\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "    # Transform the test data\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "    # Train a Logistic Regression model\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Baseline Model Accuracy: {accuracy}\")\n",
        "    print(f\"Baseline Model F1 Score: {f1}\")\n",
        "\n",
        "    # Save the trained model and vectorizer\n",
        "    joblib.dump(model, model_output_path)\n",
        "    joblib.dump(tfidf_vectorizer, vectorizer_output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_baseline_model(\n",
        "        '/content/Data/cleaned_emails.csv',\n",
        "        '/content/models/baseline_model.joblib',\n",
        "        '/content/models/tfidf_vectorizer.joblib'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhFMv9ThCva5",
        "outputId": "dd8f511c-98e2-4597-984c-540c3da9cf72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model Accuracy: 0.9953051643192489\n",
            "Baseline Model F1 Score: 0.9952978860372445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer, IntervalStrategy\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
        "\n",
        "def train_transformer_model(input_file, model_output_dir):\n",
        "    # Load the cleaned dataset\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Map labels to integers\n",
        "    unique_labels = df['label'].unique()\n",
        "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
        "    int_to_label = {i: label for i, label in enumerate(unique_labels)}\n",
        "    df['label_int'] = df['label'].map(label_to_int)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['reply'], df['label_int'], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Tokenize data\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    train_encodings = tokenize_function(X_train.tolist())\n",
        "    test_encodings = tokenize_function(X_test.tolist())\n",
        "\n",
        "    # Create Hugging Face Dataset\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'input_ids': train_encodings['input_ids'],\n",
        "        'attention_mask': train_encodings['attention_mask'],\n",
        "        'labels': y_train.tolist()\n",
        "    })\n",
        "    test_dataset = Dataset.from_dict({\n",
        "        'input_ids': test_encodings['input_ids'],\n",
        "        'attention_mask': test_encodings['attention_mask'],\n",
        "        'labels': y_test.tolist()\n",
        "    })\n",
        "\n",
        "    # Load model\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=len(unique_labels)\n",
        "    )\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_output_dir,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        # logging_dir='./logs', # Removed for simplicity\n",
        "        # logging_steps=10, # Removed for simplicity\n",
        "        # evaluation_strategy=IntervalStrategy.EPOCH, # Removed due to TypeError\n",
        "        # save_strategy=IntervalStrategy.EPOCH, # Removed due to TypeError\n",
        "        # load_best_model_at_end=True, # Removed due to TypeError\n",
        "        # metric_for_best_model=\"f1\", # Removed due to TypeError\n",
        "        report_to=\"none\" # Disable reporting to services like W&B\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the fine-tuned model\n",
        "    trainer.save_model(model_output_dir)\n",
        "    tokenizer.save_pretrained(model_output_dir)\n",
        "\n",
        "    # Save label mappings\n",
        "    pd.DataFrame([int_to_label]).to_csv(f\"{model_output_dir}/label_mapping.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_transformer_model(\n",
        "        '/content/Data/cleaned_emails.csv',\n",
        "        '/content/models/distilbert_finetuned'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "GC4La2orDGyZ",
        "outputId": "5e0d94be-68c0-4812-ba31-e19a8d8256d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [639/639 07:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.226100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def evaluate_baseline_model(input_file, model_path, vectorizer_path):\n",
        "    df = pd.read_csv(input_file)\n",
        "    X = df['reply']\n",
        "    y = df['label']\n",
        "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = joblib.load(model_path)\n",
        "    vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "def evaluate_transformer_model(input_file, model_dir):\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Load label mapping\n",
        "    label_mapping_df = pd.read_csv(f\"{model_dir}/label_mapping.csv\")\n",
        "    # Ensure keys are integers\n",
        "    int_to_label = {int(k): v for k, v in label_mapping_df.iloc[0].to_dict().items()}\n",
        "    label_to_int = {v: k for k, v in int_to_label.items()}\n",
        "\n",
        "    df['label_int'] = df['label'].map(label_to_int)\n",
        "\n",
        "    X = df['reply']\n",
        "    y = df['label_int']\n",
        "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_dir)\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for text, label in zip(X_test, y_test):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred_label_int = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append(pred_label_int)\n",
        "        true_labels.append(label)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cleaned_data_path = '/content/Data/cleaned_emails.csv'\n",
        "    baseline_model_path = '/content/models/baseline_model.joblib'\n",
        "    tfidf_vectorizer_path = '/content/models/tfidf_vectorizer.joblib'\n",
        "    transformer_model_dir = '/content/models/distilbert_finetuned'\n",
        "\n",
        "    print(\"Evaluating Baseline Model...\")\n",
        "    baseline_accuracy, baseline_f1 = evaluate_baseline_model(\n",
        "        cleaned_data_path, baseline_model_path, tfidf_vectorizer_path\n",
        "    )\n",
        "    print(f\"Baseline Model - Accuracy: {baseline_accuracy:.4f}, F1 Score: {baseline_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nEvaluating Transformer Model...\")\n",
        "    transformer_accuracy, transformer_f1 = evaluate_transformer_model(\n",
        "        cleaned_data_path, transformer_model_dir\n",
        "    )\n",
        "    print(f\"Transformer Model - Accuracy: {transformer_accuracy:.4f}, F1 Score: {transformer_f1:.4f}\")\n",
        "\n",
        "    # Compare and decide\n",
        "    if transformer_f1 > baseline_f1:\n",
        "        print(\"\\nTransformer model performs better and is recommended for production.\")\n",
        "        best_model = \"Transformer\"\n",
        "    else:\n",
        "        print(\"\\nBaseline model performs better and is recommended for production.\")\n",
        "        best_model = \"Baseline\"\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        \"baseline_model\": {\n",
        "            \"accuracy\": baseline_accuracy,\n",
        "            \"f1_score\": baseline_f1\n",
        "        },\n",
        "        \"transformer_model\": {\n",
        "            \"accuracy\": transformer_accuracy,\n",
        "            \"f1_score\": transformer_f1\n",
        "        },\n",
        "        \"best_model_for_production\": best_model\n",
        "    }\n",
        "\n",
        "    with open('/content/Results/model_comparison.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "    print(\"\\nModel comparison results saved to results/model_comparison.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mARUwFT2F2eQ",
        "outputId": "3fb70b6d-2333-4ba2-8e04-fba0900dabc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Baseline Model...\n",
            "Baseline Model - Accuracy: 0.9953, F1 Score: 0.9953\n",
            "\n",
            "Evaluating Transformer Model...\n",
            "Transformer Model - Accuracy: 0.9977, F1 Score: 0.9977\n",
            "\n",
            "Transformer model performs better and is recommended for production.\n",
            "\n",
            "Model comparison results saved to results/model_comparison.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11aEDdFfo8Mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}